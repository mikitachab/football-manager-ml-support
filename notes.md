# Project notes

## Decision Tree

- [Medium Decision Tree Params Tuning](https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3)
- [Medium About Decision Trees](https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d0)

## Gradient Boost

- [Gradient Boost Params Tuning](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/)
The overall parameters can be divided into 3 categories:

- Tree-Specific Parameters: These affect each individual tree in the model.
- Boosting Parameters: These affect the boosting operation in the model.
- Miscellaneous Parameters: Other parameters for overall functioning.

## XGBoost

- [Medium About XGBoost](https://medium.com/@pushkarmandot/how-exactly-xgboost-works-a320d9b8aeef)
- [Slides About XGBoost](https://www.slideshare.net/ShangxuanZhang/xgboost)
- [Params Tuning](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/)

## Gotchas

[train test split before oversampling](https://stats.stackexchange.com/questions/60180/testing-classification-on-oversampled-imbalance-data)  
[scale before feature selection](https://stats.stackexchange.com/questions/363312/normalization-standardization-should-one-do-this-before-oversampling-undersampl)

## to checkout

- AUC (Area Under Curve) as the evaluation metric [link](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5) [video](https://www.youtube.com/watch?v=4jRBRDbJemM)
- compare train test scores

## EDA

[some help](https://towardsdatascience.com/hitchhikers-guide-to-exploratory-data-analysis-6e8d896d3f7e)
[more help](https://towardsdatascience.com/a-gentle-introduction-to-exploratory-data-analysis-f11d843b8184)